import gensim
import pandas as pd
import time
import pickle
import os

DATASET_FILE_PATH = 'dataset/cve_dataset.csv'
WORD_EMBEDDING_FOLDER_PATH = 'word_embeddings'


class DataLoader(object):
    """Helper class to get words in the dataset."""

    def __init__(self, file_path=None):
        if file_path is None:
            file_path = DATASET_FILE_PATH

        self.cve_df = pd.read_csv(file_path)

    def __iter__(self):
        """Returns each word in cleaned description sentences."""
        for s in self.cve_df['description_cleaned'].str.split():
            yield s


def get_sentences():
    """Helper function to return all sentences in the dataset
    Sentences are represented as a list of words
    Returns:
        list of sentences
    """

    data_loader = DataLoader()
    return list(data_loader)


def build_word2vec_model(sentences, min_count=2, vector_dim=300):
    """Generates word2vec model and builds vocabulary
    
    Args:
        sentences (list): List of sentences. Each sentence in the list
            is a list of words
        min_count (optional): Minimum occurences of a word required to add
            the word to vocabulary. Default: 2
        vector_dim (optional): word2vec output vector dimension

    Returns:
        model
    """

    model = gensim.models.Word2Vec(min_count=min_count, size=vector_dim,
                                   workers=4, sg=1, window=5)
    model.build_vocab(sentences)

    return model


def train_word2vec_model(sentences, model, epochs=100):
    """Trains word2vec model by given sentences

    Args:
        sentences (list): List of sentences. Each sentence in the list
            is a list of words
        model (obj): word2vec model object
        epochs (optional): Training epochs

    Returns:
        trained model
    """

    start_time = time.time()
    print("Training started for {} words".format(model.corpus_count))

    model.train(sentences, total_examples=model.corpus_count, epochs=epochs)

    print("Training completed in {} seconds".format(time.time() - start_time))

    return model


def save_word_vectors(model, out_file_name="word2vec_vectors.pickle"):
    """Serializes and saves a dictionary of word2vec vectors

    Args:
        model (obj): Trained word2vec model
        out_file_name (optional): Output file name
    """

    word_dict = {}
    for word in model.wv.vocab.keys():
        word_dict[word] = model.wv[word]

    # Create output directory if they don't exist
    if not os.path.exists(WORD_EMBEDDING_FOLDER_PATH):
        os.makedirs(WORD_EMBEDDING_FOLDER_PATH)

    out_file_path = WORD_EMBEDDING_FOLDER_PATH + "/" + out_file_name
    with open(out_file_path, 'wb') as f:
        pickle.dump(word_dict, f, protocol=pickle.HIGHEST_PROTOCOL)

    print('Saved word2vec vectors succesfully to {}'.format(out_file_path))


if __name__ == "__main__":
    sentences = get_sentences()
    model = build_word2vec_model(sentences)
    model = train_word2vec_model(sentences, model)
    save_word_vectors(model)
